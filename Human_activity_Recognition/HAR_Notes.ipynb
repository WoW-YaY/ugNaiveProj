{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据滤波与提取\n",
    "> 这一步首先对原始数据进行滤波，然后通过步长为128的窗口以50%的重叠率把每次采集的数据整理成若干条数据，再对每一条数据进行特征提取转化成可以作为模型输入的features。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tips: 微信小程序数据库中直接导出的是若干500\\*6的.csv表格，每一行代表记录的时刻（以20ms为间隔，从1～500编号），每一列代表某传感器某一轴的测量值（ax,ay,az,gx,gy,gz），每一张表格以“ai-j.csv”命名，表示动作i的第j次数据采集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先导入必要的包\n",
    "import numpy as np\n",
    "from scipy import signal as signal\n",
    "\n",
    "# 声明待处理的文件路径，批量化处理时更改此处即可，提高模块化程度\n",
    "data_No = './data/a1-5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来定义三个后面可能用到的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把数据以50%的overlap进行拆分，每个窗口长度为128个（2.56秒），同时分出六个轴\n",
    "# 输出：6个6*128的表格\n",
    "def spl(data):\n",
    "    ax = np.zeros((6,128))\n",
    "    for i in range(6):\n",
    "        ax[i,:] = data[0,i*64:i*64+128]\n",
    "    ay = np.zeros((6,128))\n",
    "    for i in range(6):\n",
    "        ay[i,:] = data[1,i*64:i*64+128]\n",
    "    az = np.zeros((6,128))\n",
    "    for i in range(6):\n",
    "        az[i,:] = data[2,i*64:i*64+128]\n",
    "    gx = np.zeros((6,128))\n",
    "    for i in range(6):\n",
    "        gx[i,:] = data[3,i*64:i*64+128]\n",
    "    gy = np.zeros((6,128))\n",
    "    for i in range(6):\n",
    "        gy[i,:] = data[4,i*64:i*64+128]\n",
    "    gz = np.zeros((6,128))\n",
    "    for i in range(6):\n",
    "        gz[i,:] = data[5,i*64:i*64+128]\n",
    "    return ax,ay,az,gx,gy,gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 滤波\n",
    "def filtering(data):\n",
    "    rows = data.shape[0]\n",
    "# 中值滤波\n",
    "    for i in range(rows):\n",
    "        data[i,:] = signal.medfilt(data[i,:],3)\n",
    "# 巴特沃斯低通滤波\n",
    "    b, a = signal.butter(3, 0.8, 'lowpass')\n",
    "    for i in range(rows):\n",
    "        data[i,:] = signal.filtfilt(b,a,data[i,:])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成特征值\n",
    "# 这一步需要根据试验情况调整生成特征值的种类\n",
    "# 实践中发现，过多的特征值会导致模型计算中有一步出现overflow的情况，同时不利于小程序的部署\n",
    "# 因此特征选择尽量少且具有代表性\n",
    "def generate_feature(data):\n",
    "    f = np.zeros((6,1))\n",
    "    f[:,0] = np.mean(data,axis=1)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对具体数据进行操作\n",
    "df = np.loadtxt(data_No+'.csv',skiprows=1,usecols = (1,2,3,4,5,6),delimiter = ',')  # 首先把数据读进来（跳过第一列的编号）\n",
    "filtered = filtering(df.T)  # 把表格转置一下然后滤波\n",
    "ax,ay,az,gx,gy,gz = spl(filtered)  # 按照步长128重叠率50%进行拆分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将上面得到的处理完的数据进行操作得到features\n",
    "fax = generate_feature(ax)\n",
    "fay = generate_feature(ay)\n",
    "faz = generate_feature(az)\n",
    "fgx = generate_feature(gx)\n",
    "fgy = generate_feature(gy)\n",
    "fgz = generate_feature(gz)\n",
    "\n",
    "# 把六个轴得到的features整合到一张表中\n",
    "F = np.hstack((fax,fay,faz,fgx,fgy,fgz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导出最后生成的features表格\n",
    "np.savetxt(data_No+'features.csv',F,delimiter = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型构建与训练\n",
    "> 模型部分选用的是朴素贝叶斯分类器(Naive Bayes Classifier)，选用该算法是基于一个假设，即不同人做同一动作的体态应该服从高斯分布。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先导入必要的包\n",
    "import numpy as np\n",
    "\n",
    "# 加载features和labels表格\n",
    "X_train = np.loadtxt('features.csv',usecols = (0,1,2,3,4,5),delimiter = ',')\n",
    "# X_train = np.loadtxt('features.txt')\n",
    "Y_train = np.loadtxt('targets.txt',dtype=int)\n",
    "data_dim = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照所属类别对训练数据进行拆分\n",
    "X_train_0 = np.array([x for x, y in zip(X_train, Y_train) if y == 0])\n",
    "X_train_1 = np.array([x for x, y in zip(X_train, Y_train) if y == 1])\n",
    "X_train_2 = np.array([x for x, y in zip(X_train, Y_train) if y == 2])\n",
    "X_train_3 = np.array([x for x, y in zip(X_train, Y_train) if y == 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算每一个类别的类内均值\n",
    "mean_0 = np.mean(X_train_0, axis = 0)\n",
    "mean_1 = np.mean(X_train_1, axis = 0)\n",
    "mean_2 = np.mean(X_train_2, axis = 0)\n",
    "mean_3 = np.mean(X_train_3, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算每一个类别的类内方差\n",
    "cov_0 = np.zeros((data_dim, data_dim))\n",
    "cov_1 = np.zeros((data_dim, data_dim))\n",
    "cov_2 = np.zeros((data_dim, data_dim))\n",
    "cov_3 = np.zeros((data_dim, data_dim))\n",
    "\n",
    "for x in X_train_0:\n",
    "    cov_0 += np.dot(np.transpose([x - mean_0]), [x - mean_0]) / X_train_0.shape[0]\n",
    "for x in X_train_1:\n",
    "    cov_1 += np.dot(np.transpose([x - mean_1]), [x - mean_1]) / X_train_1.shape[0]\n",
    "for x in X_train_2:\n",
    "    cov_2 += np.dot(np.transpose([x - mean_2]), [x - mean_2]) / X_train_2.shape[0]\n",
    "for x in X_train_3:\n",
    "    cov_3 += np.dot(np.transpose([x - mean_3]), [x - mean_3]) / X_train_3.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ！！！高能预警！！！\n",
    "\n",
    "以下部分可以说是模型最关键的地方，计算具体的权重w和偏差b。\n",
    "\n",
    "在对高斯分布的公式进行化简的时候，假设当前计算的两类具有相同类内方差，该方差为两类各自方差的加权平均，这个假设是为了减少模型中的参数，一方面增加模型的范化能力，另一方面方便模型在小程序上的部署。具体化简过程需要一定数学基础，在此直接呈现结果。\n",
    "\n",
    "下面的步骤一共需要重复六次，因为一共有四类，两两之间都要计算一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每两类共用一个方差，该方差为这两类方差的加权平均，下同\n",
    "cov_01 = (cov_0 * X_train_0.shape[0] + cov_1 * X_train_1.shape[0]) / (X_train_0.shape[0] + X_train_1.shape[0])\n",
    "u, s, v = np.linalg.svd(cov_01, full_matrices=False)\n",
    "inv = np.matmul(v.T * 1 / s, u.T)\n",
    "# 由此可以直接计算出权重和偏差，下同\n",
    "w01 = np.dot(inv, mean_0 - mean_1)\n",
    "b01 =  (-0.5) * np.dot(mean_0, np.dot(inv, mean_0)) + 0.5 * np.dot(mean_1, np.dot(inv, mean_1))\\\n",
    "    + np.log(float(X_train_0.shape[0]) / X_train_1.shape[0])\n",
    "\n",
    "cov_02 = (cov_0 * X_train_0.shape[0] + cov_2 * X_train_2.shape[0]) / (X_train_0.shape[0] + X_train_2.shape[0])\n",
    "u, s, v = np.linalg.svd(cov_02, full_matrices=False)\n",
    "inv = np.matmul(v.T * 1 / s, u.T)\n",
    "w02 = np.dot(inv, mean_0 - mean_2)\n",
    "b02 =  (-0.5) * np.dot(mean_0, np.dot(inv, mean_0)) + 0.5 * np.dot(mean_2, np.dot(inv, mean_2))\\\n",
    "    + np.log(float(X_train_0.shape[0]) / X_train_2.shape[0]) \n",
    "\n",
    "cov_03 = (cov_0 * X_train_0.shape[0] + cov_3 * X_train_3.shape[0]) / (X_train_0.shape[0] + X_train_3.shape[0])\n",
    "u, s, v = np.linalg.svd(cov_03, full_matrices=False)\n",
    "inv = np.matmul(v.T * 1 / s, u.T)\n",
    "w03 = np.dot(inv, mean_0 - mean_3)\n",
    "b03 =  (-0.5) * np.dot(mean_0, np.dot(inv, mean_0)) + 0.5 * np.dot(mean_3, np.dot(inv, mean_3))\\\n",
    "    + np.log(float(X_train_0.shape[0]) / X_train_3.shape[0])\n",
    "\n",
    "cov_12 = (cov_1 * X_train_1.shape[0] + cov_2 * X_train_2.shape[0]) / (X_train_1.shape[0] + X_train_2.shape[0])\n",
    "u, s, v = np.linalg.svd(cov_12, full_matrices=False)\n",
    "inv = np.matmul(v.T * 1 / s, u.T)\n",
    "w12 = np.dot(inv, mean_1 - mean_2)\n",
    "b12 =  (-0.5) * np.dot(mean_1, np.dot(inv, mean_1)) + 0.5 * np.dot(mean_2, np.dot(inv, mean_2))\\\n",
    "    + np.log(float(X_train_1.shape[0]) / X_train_2.shape[0]) \n",
    "\n",
    "cov_13 = (cov_1 * X_train_1.shape[0] + cov_3 * X_train_3.shape[0]) / (X_train_1.shape[0] + X_train_3.shape[0])\n",
    "u, s, v = np.linalg.svd(cov_13, full_matrices=False)\n",
    "inv = np.matmul(v.T * 1 / s, u.T)\n",
    "w13 = np.dot(inv, mean_1 - mean_3)\n",
    "b13 =  (-0.5) * np.dot(mean_1, np.dot(inv, mean_1)) + 0.5 * np.dot(mean_3, np.dot(inv, mean_3))\\\n",
    "    + np.log(float(X_train_1.shape[0]) / X_train_3.shape[0])\n",
    "\n",
    "cov_23 = (cov_2 * X_train_2.shape[0] + cov_3 * X_train_3.shape[0]) / (X_train_2.shape[0] + X_train_3.shape[0])\n",
    "u, s, v = np.linalg.svd(cov_23, full_matrices=False)\n",
    "inv = np.matmul(v.T * 1 / s, u.T)\n",
    "w23 = np.dot(inv, mean_2 - mean_3)\n",
    "b23 =  (-0.5) * np.dot(mean_2, np.dot(inv, mean_2)) + 0.5 * np.dot(mean_3, np.dot(inv, mean_3))\\\n",
    "    + np.log(float(X_train_2.shape[0]) / X_train_3.shape[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w01: [-2.66101376 41.79562253  7.66104293  2.64022394  0.33635261 -9.00248786] \n",
      "b01: -8.295051012701379 \n",
      "\n",
      "w02: [-81.4939717   34.61763437 263.18878502 -27.20539051  61.15050547\n",
      "  16.38442745] \n",
      "b02: 190.80706834346483 \n",
      "\n",
      "w03: [ 62.97536227  40.78850165  -5.6585328   -4.64453211   7.78903076\n",
      " -21.49121195] \n",
      "b03: -70.49755657118743\n",
      "\n",
      "\n",
      "w12: [ 2.39555501 -7.88607327 12.58942167 14.10338539 10.07135474 10.2806766 ] \n",
      "b12: 8.545704376265395 \n",
      "\n",
      "w13: [ 21.8592652    4.83530056  -7.05969533  -4.35725167  -3.82293505\n",
      " -10.29726871] \n",
      "b13: -21.240499109311852 \n",
      "\n",
      "w23: [ 11.99353123  22.69249114 -50.7814112  -10.79888599 -26.81164328\n",
      " -14.07464918] \n",
      "b23: -45.22007401575592\n"
     ]
    }
   ],
   "source": [
    "# 输出模型中的参数，便于移植到小程序上\n",
    "print(\"w01:\",w01,\"\\nb01:\",b01,\"\\n\\nw02:\",w02,\"\\nb02:\",b02,\"\\n\\nw03:\",w03,\"\\nb03:\",b03)\n",
    "print(\"\\n\\nw12:\",w12,\"\\nb12:\",b12,\"\\n\\nw13:\",w13,\"\\nb13:\",b13,\"\\n\\nw23:\",w23,\"\\nb23:\",b23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义预测函数，得到样本属于每一类的概率值，并输出它最可能属于的类别\n",
    "# 在小程序中概率的具体计算同下面公式\n",
    "def predict(x):\n",
    "    z01 = np.dot(x,w01) + b01\n",
    "    z02 = np.dot(x,w02) + b02\n",
    "    z03 = np.dot(x,w03) + b03\n",
    "    z12 = np.dot(x,w12) + b12\n",
    "    z13 = np.dot(x,w13) + b13\n",
    "    z23 = np.dot(x,w23) + b23\n",
    "    \n",
    "    p = np.zeros((4))\n",
    "    p[0] = 1 / (1 + np.exp(-z01)+ np.exp(-z02)+ np.exp(-z03))\n",
    "    p[1] = 1 / (1 + np.exp(z01) + np.exp(-z12)+ np.exp(-z13))\n",
    "    p[2] = 1 / (1 + np.exp(z02) + np.exp(z12) + np.exp(-z23))\n",
    "    p[3] = 1 / (1 + np.exp(z03) + np.exp(z13) + np.exp(z23))\n",
    "    \n",
    "    #print(p)\n",
    "    print(np.argmax(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
